# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QssQnHMPXNvSHe3VZc_cUWDPbHu94AUO
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle

!pip install pandas scikit-learn matplotlib seaborn

import pandas as pd

def load_and_clean_data(file_path):
    # Load the dataset
    df = pd.read_csv(file_path)

    # Check for missing values
    df = df.dropna()  # Drop rows with missing values

    # You can add more cleaning steps as needed
    return df

if __name__ == "__main__":
    df = load_and_clean_data('weather_data.csv')
    print(df.head())

# Install necessary libraries
!pip install pandas scikit-learn matplotlib seaborn

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# Create dummy weather data for testing
data = {
    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']),
    'Temperature (C)': [10, 12, 15, 14, 16],
    'Humidity (%)': [60, 65, 70, 68, 72],
    'Wind Speed (km/h)': [15, 18, 20, 16, 22],
    'Rainfall (mm)': [0, 0, 5, 2, 0],
    'Pressure (hPa)': [1012, 1010, 1008, 1009, 1011],
    'Description': ['Cloudy', 'Sunny', 'Rainy', 'Partly Cloudy', 'Sunny'],
    'City': ['New York', 'New York', 'New York', 'New York', 'New York'],
    'Country': ['USA', 'USA', 'USA', 'USA', 'USA'],
    'Data.Precipitation': [0, 0, 0, 0, 0],
    'Data.Wind.Speed': [15, 18, 20, 16, 22],
    'Data.Wind.Direction': [180, 190, 200, 195, 205],
    'Data.Temperature': [10, 12, 15, 14, 16],
    'Data.Humidity': [60, 65, 70, 68, 72]
}

weather_df = pd.DataFrame(data)
weather_df.to_csv('weather_data.csv', index=False)

def load_and_clean_data(file_path):
    # Load the dataset
    try:
        df = pd.read_csv(file_path)
        print("Columns in the CSV:", df.columns) #Print Column names
    except FileNotFoundError:
        print(f"Error: File not found at {file_path}")
        return None

    # Check for missing values
    df = df.dropna()  # Drop rows with missing values

    # You can add more cleaning steps as needed
    return df

def perform_eda(df):
    if df is None:
        print("Error: DataFrame is None. Cannot perform EDA.")
        return

    # Verify the dataframe
    print(df.head())

    try:
        # Visualize the distribution of temperature
        plt.figure(figsize=(10, 6))
        sns.histplot(df['Temperature (C)'], bins=30, kde=True) #Error will occur here if the columns is not as expected
        plt.title('Temperature Distribution')
        plt.xlabel('Temperature (C)')
        plt.ylabel('Frequency')
        plt.show()

        # Correlation heatmap
        plt.figure(figsize=(10, 6))
        plt.title('Correlation Heatmap')
        plt.show()
    except KeyError as e:
        print(f"KeyError: {e}")
        print("Available columns in the DataFrame:", df.columns)

if __name__ == "__main__":
    df = load_and_clean_data('weather_data.csv')
    if df is not None:
        print(df.head())
        perform_eda(df)

# Install necessary libraries
!pip install pandas scikit-learn matplotlib seaborn

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# Create dummy weather data for testing
data = {
    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']),
    'Temperature (C)': [10, 12, 15, 14, 16],
    'Humidity (%)': [60, 65, 70, 68, 72],
    'Wind Speed (km/h)': [15, 18, 20, 16, 22],
    'Rainfall (mm)': [0, 0, 5, 2, 0],
    'Pressure (hPa)': [1012, 1010, 1008, 1009, 1011],
    'Description': ['Cloudy', 'Sunny', 'Rainy', 'Partly Cloudy', 'Sunny'],
    'City': ['New York', 'New York', 'New York', 'New York', 'New York'],
    'Country': ['USA', 'USA', 'USA', 'USA', 'USA'],
    'Data.Precipitation': [0, 0, 0, 0, 0],
    'Data.Wind.Speed': [15, 18, 20, 16, 22],
    'Data.Wind.Direction': [180, 190, 200, 195, 205],
    'Data.Temperature': [10, 12, 15, 14, 16],
    'Data.Humidity': [60, 65, 70, 68, 72],
    'Pressure (millibars)': [1012, 1010, 1008, 1009, 1011], # Added this to match the model input
    'Wind Bearing (degrees)': [180, 190, 200, 195, 205], # Added this to match the model input
    'Visibility (km)': [10, 12, 15, 14, 16] # Added this to match the model input
}

weather_df = pd.DataFrame(data)
weather_df.to_csv('weather_data.csv', index=False)

def load_and_clean_data(file_path):
    # Load the dataset
    try:
        df = pd.read_csv(file_path)
        print("Columns in the CSV:", df.columns) #Print Column names
    except FileNotFoundError:
        print(f"Error: File not found at {file_path}")
        return None

    # Check for missing values
    df = df.dropna()  # Drop rows with missing values

    # You can add more cleaning steps as needed
    return df

def perform_eda(df):
    if df is None:
        print("Error: DataFrame is None. Cannot perform EDA.")
        return

    # Verify the dataframe
    print(df.head())

    try:
        # Visualize the distribution of temperature
        plt.figure(figsize=(10, 6))
        sns.histplot(df['Temperature (C)'], bins=30, kde=True) #Error will occur here if the columns is not as expected
        plt.title('Temperature Distribution')
        plt.xlabel('Temperature (C)')
        plt.ylabel('Frequency')
        plt.show()

        # Correlation heatmap
        plt.figure(figsize=(10, 6))
        plt.title('Correlation Heatmap')
        plt.show()
    except KeyError as e:
        print(f"KeyError: {e}")
        print("Available columns in the DataFrame:", df.columns)

if __name__ == "__main__":
    df = load_and_clean_data('weather_data.csv')
    if df is not None:
        print(df.head())
        perform_eda(df)

def train_model(df):
    # Features and target variable
    # Use the corrected column names
    X = df[['Humidity (%)', 'Pressure (millibars)', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)']]
    y = df['Temperature (C)']

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Save the model
    with open('temperature_model.pkl', 'wb') as model_file:
        pickle.dump(model, model_file)

if __name__ == "__main__":
    df = load_and_clean_data('weather_data.csv') #Use load_and_clean_data to make sure we have the rigth data
    if df is not None:
      train_model(df)



"""# New Section

# New Section
"""